# configs/train_config.yaml
# Training configuration for RealPLKSR

experiment_name: nomos_uni_gt_4x

# Model configuration
model: realplksr  # realplksr, realplksr_s, realplksr_l
model_params:
  in_ch: 3
  out_ch: 3
  dim: 64
  n_blocks: 28
  kernel_size: 17
  split_ratio: 0.25
  use_ea: true
  norm_groups: 4
  dropout: 0.1
  dysample: false # disable for MPS, enable for CUDA

# Training parameters
scale: 4
iterations: 500000
batch_size: 8
patch_size: 256
num_workers: 0 # MPS works better with 0, use 4 for CUDA
seed: 42

# Datasets
train_dataset: nomos_uni_gt
val_dataset: nomos_uni_gt  # Will use same dataset with different transform

# Optimizer
optimizer: AdamW
learning_rate: 0.0001
weight_decay: 0.0001
scheduler: cosine
min_lr: 0.0000001 

# Loss weights
weight_l1: 1.0
weight_l2: 0.1
weight_ms_ssim: 0.2
weight_perceptual: 0.1

# Loss options
use_l2: false
use_ms_ssim: true
use_perceptual: false

# Training options
use_amp: false  # Mixed precision (disable for MPS)
grad_clip: 1.0
crop_border: 4

# Logging
use_wandb: false
wandb_project: RealPLKSR
log_interval: 100
save_interval: 5000
val_interval: 5000
log_images: true

# Pretrained (optional)
# pretrain_path: weights/4xmssim_realplksr_dysample_pretrain.pth
pretrain_path: weights/4xNomos2_realplksr_dysample.pth