# configs/train_config.yaml
# Training configuration for RealPLKSR - NeoSR style

experiment_name: nomos_uni_gt_4x

# Model configuration
model: realplksr
model_params:
  in_ch: 3
  out_ch: 3
  dim: 64
  n_blocks: 28
  kernel_size: 17
  split_ratio: 0.25
  use_ea: true
  norm_groups: 4
  dropout: 0.1
  dysample: false  # disable for MPS, enable for CUDA
  # Remove experimental features to match base model
  # res_scale: 0.1
  # use_layerscale: true
  # drop_path: 0.1

# Training parameters
scale: 4
iterations: 500000
batch_size: 8
patch_size: 256
num_workers: 0  # MPS works better with 0, use 4 for CUDA
seed: 42

# Datasets
train_dataset: nomos_uni_gt
val_dataset: nomos_uni_gt

# Optimizer - NeoSR style
optimizer: adan_sf
learning_rate: 0.0005  # 5e-4 for Adan
weight_decay: 0.01
warmup_steps: 1600
scheduler: cosine
min_lr: 0.0000001

# Loss weights - NeoSR style (multiple losses)
weight_l1: 1.0
weight_ms_ssim: 1.0
weight_consistency: 1.0
weight_ldl: 1.0
weight_fdl: 0.75

# Loss options - enable NeoSR losses
use_l2: false
use_ms_ssim: true
use_consistency: true
use_ldl: true
use_fdl: true

# Training options
use_amp: false  # Mixed precision (disable for MPS)
grad_clip: 1.0
crop_border: 4

# Logging
use_wandb: false
wandb_project: RealPLKSR
log_interval: 100
save_interval: 5000
val_interval: 5000
log_images: true

# Pretrained
pretrain_path: weights/4xNomos2_realplksr_dysample.pth